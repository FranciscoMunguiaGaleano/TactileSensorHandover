# TactileSensorHandover


[![Alt Text](http://img.youtube.com/vi/qP54j6ZPKLk/0.jpg)](https://www.youtube.com/watch?v=qP54j6ZPKLk)

# Aknowledgement

@InProceedings{10.1007/978-3-031-43360-3_35,
author="Rayamane, Prasad
and Munguia-Galeano, Francisco
and Tafrishi, Seyed Amir
and Ji, Ze",
editor="Iida, Fumiya
and Maiolino, Perla
and Abdulali, Arsen
and Wang, Mingfeng",
title="Towards Smooth Human-Robot Handover with a Vision-Based Tactile Sensor",
booktitle="Towards Autonomous Robotic Systems",
year="2023",
publisher="Springer Nature Switzerland",
address="Cham",
pages="431--442",
abstract="Cooperative human-robot interaction often requires successful handovers of objects between the two entities. However, the assumption that a human can reliably grasp an object from a robot is not always valid. To address this issue, we propose a vision-based tactile sensor for object handover framework that utilises a low-cost sensor with variable sensitivity and pressure. The sensor comprises a latex layer that makes contact with the object and a tracking marker that registers the resulting changes in position. By pre-processing this information, a robot can determine whether it is necessary to open the gripper. Our approach is validated through an exploratory user study involving ten participants who completed handover tasks involving eight objects of varying shapes and stiffness, including rigid and deformable objects like raspberries and dough. The study results demonstrate the effectiveness of our approach, with a success rate of 94{\%}. Additionally, users reported less difficulty performing the handover tasks when the sensitivity value was decreased. Overall, our vision-based tactile sensor framework offers a promising solution for the challenging problem of human-robot handover in cooperative settings.",
isbn="978-3-031-43360-3"
}
